# DL_Compiler_and_Hardware Study

This is a repository of the study "DL Compiler and Hardware". The goal of this study is to understand the acceleration of nerual networks with DL Compiler. The topic of acceleration includes `Hardware-Aware Optimization`,`DL Compiler`, `TVM`, `ONNX` , `Compiler`, `PIM/CIM`, `NPU`. Our study is based on recent papaers (Under recent two years). We discuss topics such as `HW architecture`, `SW acceleration`.


## Presentation Order
When |  Who  | What | Links | Issue # | Etc.
---- | --------- | ----------------------------------------- | ----------------------- | --------------------- | ----
7/5 | 박상수 | Introduction to Study & MTIA v1: Meta’s first-generation AI inference accelerator | - | #1 | -
7/19 | - | - | - | #2 | -
8/02 | - | - | - | #3 | -
8/16 | - | - | - | #4 | -
8/30 | - | - | - | #5 | -
9/13 | 김정현 | FACT: FFN-Attention Co-optimized Transformer Architecture with Eager Correlation Prediction | - | #6 | -
9/27 | - | - | - | #7 | -
10/11 | - | - | - | #8 | -
10/25 |  - | - | - | #9 | -
11/08 | - | - | - | #10 | -
11/22 | - | - | - | #11 | -
12/6 | - | - | - | #12 | -
12/20 | - | - | - | #13 | -
